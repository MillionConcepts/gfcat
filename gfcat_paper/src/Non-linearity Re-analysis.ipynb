{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2caccef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02141154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from lightcurve_interface_skeleton import load_lightcurve_records\n",
    "import os\n",
    "from scipy import signal, stats\n",
    "from rich import print\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78140aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(19470622) # the birthdate of Bruno Latour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7361df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_data = pd.read_csv('../ref/mislike_image_header_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6e2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_filename = '../ref/catalog_nd_daostarfinder.parquet'\n",
    "catalog_file = pq.ParquetFile(catalog_filename)\n",
    "#catalog = parquet.read_table(catalog_fn)\n",
    "#catalog_file.read_row_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3caa082f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min, sys: 16.3 s, total: 4min 16s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">363</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m363\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_bright_stars(catalog_file,header_data,n_ecl=100):\n",
    "    targets=[]\n",
    "    scrambled_ecl = np.random.choice(len(header_data),size=len(header_data),replace=False)\n",
    "    #while len(np.unique(np.array(targets)[:,0]))<n_ecl:\n",
    "    for ix in np.random.choice(len(header_data),size=n_ecl,replace=False):\n",
    "        visit = header_data.iloc[ix]\n",
    "        eclipse = int(visit['ECLIPSE'])\n",
    "        #print(eclipse)\n",
    "        if visit['EXPTIME']<1500.0:\n",
    "            continue\n",
    "        bright_stars = pq.read_table(catalog_filename,filters =\n",
    "                                     [('aperture_sum_mask_n_51_2','=',0.0),\n",
    "                                      ('aperture_sum_edge_n_51_2','=',0.0),\n",
    "                                      ('aperture_sum_n_51_2','>',50000.0),\n",
    "                                      ('eclipse','=',eclipse)]).to_pandas()\n",
    "\n",
    "        cps = np.array(bright_stars['aperture_sum_n_51_2'])/visit['EXPTIME']\n",
    "        ix = np.where(cps>100)\n",
    "        if not len(cps[ix]):\n",
    "            #print(f'No bright stars in e{str(eclipse).zfill(5)}')\n",
    "            continue\n",
    "        X = list(zip(bright_stars['xcenter'].iloc[ix].tolist(),bright_stars['ycenter'].iloc[ix].tolist()))\n",
    "        db = DBSCAN(eps=40,min_samples=1).fit(X)\n",
    "        labels=db.labels_\n",
    "        for lbl in set(labels):\n",
    "            dbix = np.where(labels==lbl)[0]\n",
    "            brightest_ix = np.argmax(cps[ix][dbix])\n",
    "            star = bright_stars.iloc[ix].iloc[dbix].iloc[brightest_ix]\n",
    "            cps_12_8,cps_51_2 = (star['aperture_sum_n_12_8']/visit['EXPTIME'],\n",
    "                                 star['aperture_sum_n_51_2']/visit['EXPTIME'])\n",
    "            if cps_12_8<=100:\n",
    "                continue\n",
    "            # a huge discrepancy between aperture sizes probably means nearby bright stars / field\n",
    "            if cps_51_2-cps_12_8 > 50:\n",
    "                continue\n",
    "            #print(eclipse,int(star['obj_id']),cps_12_8,cps_51_2,cps_51_2-cps_12_8)\n",
    "            targets+=[[eclipse,int(star['obj_id'])]]\n",
    "    return targets\n",
    "\n",
    "%time targets = find_bright_stars(catalog_file,header_data,n_ecl=1000)\n",
    "#print(targets)\n",
    "print(len(np.unique(np.array(targets)[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a812cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lc_summary_stats(lc):\n",
    "    ad = stats.anderson(lc['cps'])  # standard test of variability\n",
    "    return {\n",
    "        'mad':np.mean(np.abs(lc['cps'] - np.mean(lc['cps']))),\n",
    "        'start_cps':np.median(lc['cps'][:5]),\n",
    "        'end_cps':np.median(lc['cps'][-6:-1]), # exclude the last bin, which is often low-expt\n",
    "        'med_std':np.median(lc['cps_err']),\n",
    "        'ad_statistic':ad.statistic,\n",
    "        'ad_critical_val':ad.critical_values[2], # 5%\n",
    "        'xcenter':lc['xcenter'],\n",
    "        'ycenter':lc['ycenter'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4530ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/home/ubuntu/datadir'\n",
    "for eclipse in np.unique(np.array(targets)[:,0]):\n",
    "    fn = f'{datadir}/e{str(eclipse).zfill(5)}-30-photom.parquet'\n",
    "    if os.path.exists(fn):\n",
    "        continue\n",
    "    cmd = f'aws s3 cp s3://dream-pool/e{str(eclipse).zfill(5)}/e{str(eclipse).zfill(5)}-30s-photom.parquet {datadir}/.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aaa9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8f33dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Failed to open local file '/home/ubuntu/datadir/e01428-30-photom.parquet'. Detail: [errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatadir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/e\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(eclipse)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-30-photom.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m aper_radius \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m51.2\u001b[39m\n\u001b[0;32m----> 4\u001b[0m lightcurves \u001b[38;5;241m=\u001b[39m \u001b[43mload_lightcurve_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNUV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapersize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maper_radius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m variables \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lc \u001b[38;5;129;01min\u001b[39;00m lightcurves:\n",
      "File \u001b[0;32m~/github/gfcat_paper/src/lightcurve_interface_skeleton.py:138\u001b[0m, in \u001b[0;36mload_lightcurve_records\u001b[0;34m(lightcurve_parquet, band, apersize)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m\"\"\"load lightcurve records from a lightcurve parquet file\"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# dataframe containing unflagged bins from specified band and aperture size,\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# and ndarray with exptime per bin\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m table, exptime \u001b[38;5;241m=\u001b[39m \u001b[43mload_unflagged\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightcurve_parquet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mband\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapersize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# select time-series data out for conversion to cps\u001b[39;00m\n\u001b[1;32m    140\u001b[0m lightcurves \u001b[38;5;241m=\u001b[39m table[curve_fields(table)]\n",
      "File \u001b[0;32m~/github/gfcat_paper/src/lightcurve_interface_skeleton.py:84\u001b[0m, in \u001b[0;36mload_unflagged\u001b[0;34m(lightcurve_file, size, band)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_unflagged\u001b[39m(\n\u001b[1;32m     77\u001b[0m     lightcurve_file: Pathlike, size: Optional[\u001b[38;5;28mfloat\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, band: GalexBand\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUV\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    load just the curves from a lightcurve parquet file for a specific aperture size \u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    (by default the smallest) and band (by default NUV) with no counts from mask or \u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    edge backplanes\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParquetFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightcurve_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     data \u001b[38;5;241m=\u001b[39m data_fields(file\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mnames)\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gfcat/lib/python3.9/site-packages/pyarrow/parquet/__init__.py:277\u001b[0m, in \u001b[0;36mParquetFile.__init__\u001b[0;34m(self, source, metadata, common_metadata, read_dictionary, memory_map, buffer_size, pre_buffer, coerce_int96_timestamp_unit, decryption_properties)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, common_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m              read_dictionary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    274\u001b[0m              pre_buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, coerce_int96_timestamp_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m              decryption_properties\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader \u001b[38;5;241m=\u001b[39m ParquetReader()\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_memory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecryption_properties\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommon_metadata \u001b[38;5;241m=\u001b[39m common_metadata\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nested_paths_by_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_nested_paths()\n",
      "File \u001b[0;32m~/miniconda3/envs/gfcat/lib/python3.9/site-packages/pyarrow/_parquet.pyx:1211\u001b[0m, in \u001b[0;36mpyarrow._parquet.ParquetReader.open\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gfcat/lib/python3.9/site-packages/pyarrow/io.pxi:1659\u001b[0m, in \u001b[0;36mpyarrow.lib.get_reader\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gfcat/lib/python3.9/site-packages/pyarrow/io.pxi:1650\u001b[0m, in \u001b[0;36mpyarrow.lib.get_native_file\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gfcat/lib/python3.9/site-packages/pyarrow/io.pxi:928\u001b[0m, in \u001b[0;36mpyarrow.lib.OSFile.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gfcat/lib/python3.9/site-packages/pyarrow/io.pxi:938\u001b[0m, in \u001b[0;36mpyarrow.lib.OSFile._open_readable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gfcat/lib/python3.9/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gfcat/lib/python3.9/site-packages/pyarrow/error.pxi:113\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Failed to open local file '/home/ubuntu/datadir/e01428-30-photom.parquet'. Detail: [errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "for eclipse in np.unique(np.array(targets)[:,0])[0:1]:\n",
    "    fn = f'{datadir}/e{str(eclipse).zfill(5)}-30-photom.parquet'\n",
    "    aper_radius = 51.2\n",
    "    lightcurves = load_lightcurve_records(fn, 'NUV', apersize=aper_radius)\n",
    "    \n",
    "    variables = {}\n",
    "    for lc in lightcurves:\n",
    "        if lc['obj_id'] in obj_ids:\n",
    "            variables[lc['obj_id']] = lc\n",
    "    for obj_id in obj_ids:\n",
    "        if obj_id not in variables.keys():\n",
    "            print(f'{obj_id} not found in {eclipse} {band} unflagged lightcurves')\n",
    "            \n",
    "    bright_star_table = pd.DataFrame()\n",
    "    for k in variables.keys():\n",
    "        lc = variables[k]\n",
    "        print(k)\n",
    "        plt.figure(figsize=(12,1))\n",
    "        plt.errorbar(range(len(lc['cps'])),lc['cps'],\n",
    "                     yerr=lc['cps_err'],fmt='k-')\n",
    "        plt.xticks([])\n",
    "        summary_stats = get_lc_summary_stats(lc)\n",
    "        summary_stats['obj_id']=int(k)\n",
    "        summary_stats['eclipse']=int(str(k)[-5:])\n",
    "        bright_star_table = bright_star_table.append(pd.Series(summary_stats),ignore_index=True)\n",
    "bright_star_table = bright_star_table.astype({'obj_id':int,'eclipse':int})\n",
    "print(bright_star_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(get_lc_summary_stats(lc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_star_table.append(pd.Series(get_lc_summary_stats(lc)),ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512cc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame().to_csv('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
